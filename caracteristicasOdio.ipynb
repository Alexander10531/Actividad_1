{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Universidad Internacional de La Rioja (UNIR) - M√°ster Universitario en Inteligencia Artificial - Procesamiento del Lenguaje Natural** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Datos del alumno (Nombre y Apellidos): Alexander Ismael Tejeda Barahona\n",
    "\n",
    "Fecha: 25-Noviembre-2025\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20pt; font-weight: bold; color: #0098cd;\">Trabajo: Caracterizaci√≥n de textos</span>\n",
    "\n",
    "**Objetivos** \n",
    "\n",
    "Con esta actividad se tratar√° de que el alumno se familiarice con el manejo de la librer√≠a spacy, as√≠ como con los conceptos b√°sicos de manejo de las t√©cnicas NER\n",
    "\n",
    "**Descripci√≥n**\n",
    "\n",
    "En esta actividad debes procesar de forma autom√°tica un texto en lenguaje natural para detectar caracter√≠sticas b√°sicas en el mismo, y para identificar y etiquetar las ocurrencias de conceptos como localizaci√≥n, moneda, empresas, etc.\n",
    "\n",
    "En la primera parte del ejercicio se proporciona un c√≥digo fuente a trav√©s del cual se lee un archivo de texto y se realiza un preprocesado del mismo. En esta parte el alumno tan s√≥lo debe ejecutar y entender el c√≥digo proporcionado.\n",
    "\n",
    "En la segunda parte del ejercicio se plantean una serie de preguntas que deben ser respondidas por el alumno. Cada pregunta deber√° responderse con un fragmento de c√≥digo fuente que est√© acompa√±ado de la explicaci√≥n correspondiente. Para elaborar el c√≥digo solicitado, el alumno deber√° visitar la documentaci√≥n de la librer√≠a spacy, cuyos enlaces se proporcionar√°n donde corresponda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1: carga y preprocesamiento del texto a analizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se agregan comentarios para definir que el equipo en el que se esta usando el proyecto sea el correcto, para mi caso lo que hice fue crear un entorno virtual con python 3.9.13 ya que el python global que tenia en mi computadora era el 3.14 el cual tenia problemas de compatibilidad con spacy, por lo que esta linea unicamente se necesita en caso de que tengas un problema similar al mio, a su vez en caso de que se necesite implementar el codigo paso a paso es necesario tambien instalar pathlib y el set de idioma que importa llamado \"es_core_news_md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INFORMACI√ìN DEL KERNEL\n",
      "============================================================\n",
      "Versi√≥n de Python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]\n",
      "Ejecutable de Python: c:\\Users\\alexa\\venv39\\Scripts\\python.exe\n",
      "Directorio de trabajo: c:\\Users\\alexa\\OneDrive\\Escritorio\\Clases\\muinar02_actividad transversal_IA_profesionalizante\n",
      "============================================================\n",
      "‚úì Est√°s usando el entorno virtual venv39 (CORRECTO)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# DIAGN√ìSTICO: Verificar qu√© Python est√° usando el kernel\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"INFORMACI√ìN DEL KERNEL\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Versi√≥n de Python: {sys.version}\")\n",
    "print(f\"Ejecutable de Python: {sys.executable}\")\n",
    "print(f\"Directorio de trabajo: {os.getcwd()}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verificar si est√° usando el entorno virtual correcto\n",
    "if \"venv39\" in sys.executable:\n",
    "    print(\"‚úì Est√°s usando el entorno virtual venv39 (CORRECTO)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è NO est√°s usando el entorno virtual venv39\")\n",
    "    print(f\"   Ruta actual: {sys.executable}\")\n",
    "    print(f\"   Ruta esperada deber√≠a contener: venv39\")\n",
    "    print(\"\\nüí° SOLUCI√ìN: Cambia el kernel a 'Python 3.9 (venv39)'\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa las diferentes librer√≠as que se est√°n importando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "import csv\n",
    "import es_core_news_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente c√≥digo simplemente carga y preprocesa el texto. Para ello, lo primero que hace es cargar un modelo de lenguaje previamente entrenado. En este caso, se utiliza <i>es_core_news_md</i>: \n",
    "\n",
    "https://spacy.io/models/es#es_core_news_md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = es_core_news_md.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objeto <i>nlp</i> permite utilizar el modelo de lenguaje cargado, de forma que se puede procesar un texto y obtenerlo en su versi√≥n preprocesada. As√≠, nos permite realizar las diferentes tareas. En este caso, vamos a utilizar el pipeline para hacer un preprocesamiento b√°sico, que consiste en tokenizar el texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparar(texto):\n",
    "    try:\n",
    "        return texto.encode(\"latin-1\").decode(\"utf-8\")\n",
    "    except:\n",
    "        return texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previo a la ejecucion del siguiente archivo se recomienda primero hacerle un pre-procesado de la informacion al dataset en este caso el tratamiento que se genero fue el siguiente con el nombre de dataset 02Dataset_anonimizado.csv\n",
    "\n",
    "1. Primero el archivo se le aplica una primera correccion, ya que el mismo tenia problemas de codificado, se codifican todos los caracteres extranios y mojikabe, esto lo podemos hacer ejecutando el script [firstStep2Clean.py] - Este script no es de mi autoria fue copiado de uno de los foros de UNIR. \n",
    "2. Sin embargo al aplicarle esta primera limpieza podemos denotar que aun tenemos algunos problemas de doble decodificacion probablmente producto de que se haya encodeado con cierto formato primero y luego con otro resultando en un problema de doble decoficicacion (Pueden observar esto en el archivo comentarios_limpio_utf8.csv, si se ejecuto el paso #1 descrito en este bloque) Con el archivo resultante del paso #1 podemos generar un segundo archivo llamado comentairos_limpio_utf8_definitivo.csv, el metodo utilizado fue generar un diccionario de caracteres mal encodeados e iterar la columan mayormente afectada, en este caso la columna \"CONTENIDO A ANALIZAR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./comentarios_limpio_utf8_definitivo.csv\"\n",
    "lines_number = 1000\n",
    "data = pd.read_csv(filename, nrows=lines_number, sep=';');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El c√≥digo anterior carga el archivo CSV (opcionalmente con un l√≠mite de l√≠neas a leer) y genera la variable <i>data</i>, que contiene un Dataframe (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) con los datos le√≠dos del CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Te vendr√° bien conocer la siguiente documentaci√≥n:\n",
    "<ul>\n",
    "    <li>https://spacy.io/api/doc</li>\n",
    "    <li>https://spacy.io/api/token</li>\n",
    "    <li>https://spacy.io/api/morphology#morphanalysis</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground\n",
    "\n",
    "Utiliza este espacio para hacer pruebas y ensayos con las variables generadas con el c√≥digo previo. A modo de ejemplo, se ofrece c√≥digo que realiza las siguientes tareas: \n",
    "\n",
    "\n",
    "- leer un n√∫mero dado de l√≠neas del Dataframe y generar dos listas con los valores (se pueden leer directamente del DataFrame, se muestra el ejemplo como una opci√≥n m√°s)\n",
    "- procesar el texto de cada comentario\n",
    "\n",
    "\n",
    "Para procesarlo, hay utilizar el objeto <i>nlp</i> y as√≠ obtener objetos de la clase <i>Doc</i> (https://spacy.io/api/doc)\n",
    "\n",
    "Visita la documentaci√≥n de dicha clase y experimenta probando las diferentes funciones y atributos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./comentarios_limpio_utf8_definitivo.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m lines_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(filename, nrows\u001b[38;5;241m=\u001b[39mlines_number, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m);\n\u001b[0;32m      4\u001b[0m doc \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m value \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "filename = \"./comentarios_limpio_utf8_definitivo.csv\"\n",
    "lines_number = 1000\n",
    "data = pd.read_csv(filename, nrows=lines_number, sep=';');\n",
    "doc = []\n",
    "value = []\n",
    "\n",
    "#con el bucle, generamos sendas listas con los comentarios ya parseados y con el valor de intensidad\n",
    "for i in range(0, lines_number):\n",
    "    \n",
    "    #en un primer paso se parsea el comentario. En el segundo paso se a√±ade el objeto a la lista\n",
    "    tmp_doc = nlp(data[\"CONTENIDO A ANALIZAR\"][i])\n",
    "    doc.append(tmp_doc)\n",
    "    \n",
    "    #en un primer paso extrae el valor. En el segundo paso se a√±ade el valor a la lista\n",
    "    tmp_value = data[\"INTENSIDAD\"][i]\n",
    "    value.append(tmp_value)\n",
    "\n",
    "\n",
    "#ejemplo de c√≥mo recorrer un comentario palabra por palabra    \n",
    "#for token in doc[1]:\n",
    "    #print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 1.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¬øCu√°ntos registros contiene el corpus?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso hay que tener mucho cuidado, dado que la primera impresion pudiese fallar, al analizar el archivo con un editor de texto vemos que tenemos 668,078 lo cual es una respuesta incorrecta porque al momento de analizar el dataset podemos observar que tenemos algunos saltos de linea, en este caso en lugar de limpiar esos saltos de linea, lo que haremos unicamente cargar nuestro dataframe y determinar la cantidad de lines guardados, algo a tener en consideracion es que si se quiere evaluar todo el dataset la mejor forma de hacerla es esta, en lugar de definir de manera harcodeada un numero constante por si el corpus llegase aumentar, al momento de la ejecucion el tamanio del corpus es de 575029"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros en el corpus: 575029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22728\\1047094039.py:1: DtypeWarning: Columns (6,7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(filename, sep=';')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(filename, sep=';')\n",
    "total_number_lines = len(data)\n",
    "print(f\"Total de registros en el corpus: {total_number_lines}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aqu√≠, debajo de la l√≠nea, la explicaci√≥n de tu respuesta</b>\n",
    "<hr>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 2.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¬øCu√°ntas palabras totales hay en los comentarios del corpus?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONTEO DE PALABRAS USANDO SPACY\n",
      "============================================================\n",
      "Total de palabras en el corpus: 51,403\n",
      "Total de documentos procesados: 1,000\n",
      "============================================================\n",
      "Nota: Se cuentan √∫nicamente tokens alfab√©ticos (palabras)\n",
      "      Se excluyen: puntuaci√≥n, espacios, n√∫meros y s√≠mbolos\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Usando spacy para contar palabras totales en el corpus\n",
    "# spacy tokeniza el texto y proporciona atributos √∫tiles para filtrar tokens\n",
    "# token.is_alpha identifica tokens que son palabras alfab√©ticas (excluye puntuaci√≥n, n√∫meros, espacios)\n",
    "\n",
    "total_palabras = 0\n",
    "\n",
    "# Iterar sobre cada documento procesado por spacy\n",
    "for documento in doc:\n",
    "    # Contar solo tokens que son palabras alfab√©ticas usando el atributo is_alpha de spacy\n",
    "    # Esto excluye autom√°ticamente: puntuaci√≥n, espacios, n√∫meros, s√≠mbolos\n",
    "    palabras_en_documento = sum(1 for token in documento if token.is_alpha)\n",
    "    total_palabras += palabras_en_documento\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CONTEO DE PALABRAS USANDO SPACY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total de palabras en el corpus: {total_palabras:,}\")\n",
    "print(f\"Total de documentos procesados: {len(doc):,}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Nota: Se cuentan √∫nicamente tokens alfab√©ticos (palabras)\")\n",
    "print(f\"      Se excluyen: puntuaci√≥n, espacios, n√∫meros y s√≠mbolos\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aqu√≠, debajo de la l√≠nea, la explicaci√≥n de tu respuesta</b>\n",
    "<hr>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso lo que estamos haciendo, es tomar el contenido del apartado anterior, el que guardamos dentro de la variable doc que representa cada una de las variables a analizar y luego de eso tokenizarlo a partir de spacy, con spacy determinamos si cada uno de los token es una palabra alfabetica, si es una palabra alfabetica entonces se suma 1 por cada uno de los ifs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 3.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¬øCu√°l el n√∫mero promedio de palabras en cada comentario?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PROMEDIO DE PALABRAS POR COMENTARIO (USANDO SPACY)\n",
      "============================================================\n",
      "Promedio de palabras por comentario: 51.40\n",
      "Total de palabras en el corpus: 51,403\n",
      "Total de comentarios procesados: 1,000\n",
      "============================================================\n",
      "Nota: El total de palabras fue calculado usando spacy en el ejercicio anterior\n",
      "      M√©todo: token.is_alpha (excluye puntuaci√≥n, espacios, n√∫meros)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Calcular el promedio de palabras por comentario usando spacy\n",
    "# Utilizamos el total de palabras ya calculado en el ejercicio anterior (total_palabras)\n",
    "# que fue obtenido usando spacy con token.is_alpha\n",
    "\n",
    "promedio_palabras = total_palabras / len(doc) if len(doc) > 0 else 0\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PROMEDIO DE PALABRAS POR COMENTARIO (USANDO SPACY)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Promedio de palabras por comentario: {promedio_palabras:.2f}\")\n",
    "print(f\"Total de palabras en el corpus: {total_palabras:,}\")\n",
    "print(f\"Total de comentarios procesados: {len(doc):,}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Nota: El total de palabras fue calculado usando spacy en el ejercicio anterior\")\n",
    "print(f\"      M√©todo: token.is_alpha (excluye puntuaci√≥n, espacios, n√∫meros)\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aqu√≠, debajo de la l√≠nea, la explicaci√≥n de tu respuesta</b>\n",
    "<hr>\n",
    " \n",
    "Para calcular el promedio de palabras por comentario, utilizamos el valor `total_palabras` que ya fue calculado en el ejercicio anterior (#2) usando spacy. Este enfoque es m√°s eficiente porque evita realizar una segunda iteraci√≥n sobre todos los documentos.\n",
    "\n",
    "El proceso se realiza de la siguiente manera:\n",
    "\n",
    "1. **Reutilizaci√≥n del c√°lculo previo**: Utilizamos la variable `total_palabras` que fue obtenida en el ejercicio #2 mediante:\n",
    "   - Iteraci√≥n sobre cada documento procesado por spacy (objetos `Doc`)\n",
    "   - Conteo de tokens alfab√©ticos usando `token.is_alpha` de spacy\n",
    "   - Suma acumulativa de todas las palabras del corpus\n",
    "\n",
    "2. **C√°lculo del promedio**: Simplemente dividimos `total_palabras` entre el n√∫mero total de comentarios (`len(doc)`) para obtener el promedio.\n",
    "\n",
    "**Ventajas de este enfoque**:\n",
    "- **Eficiencia**: No requiere volver a iterar sobre todos los documentos\n",
    "- **Consistencia**: Utiliza el mismo m√©todo de conteo (spacy con `token.is_alpha`) que el ejercicio anterior\n",
    "- **Claridad**: El c√≥digo es m√°s simple y directo\n",
    "- **Precisi√≥n**: El conteo se basa en la tokenizaci√≥n inteligente de spacy que respeta las reglas del idioma espa√±ol y excluye autom√°ticamente puntuaci√≥n, espacios, n√∫meros y s√≠mbolos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 4.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio) ¬øCu√°l el n√∫mero promedio de palabras en los comentarios de cada grupo?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CLASIFICACI√ìN DE COMENTARIOS\n",
      "============================================================\n",
      "Comentarios de ODIO: 748\n",
      "Comentarios de NO ODIO: 252\n",
      "PROMEDIO DE PALABRAS POR GRUPO (USANDO SPACY)\n",
      "============================================================\n",
      "Promedio de palabras en comentarios de ODIO: 22.15\n",
      "Promedio de palabras en comentarios de NO ODIO: 138.25\n",
      "============================================================\n",
      "Nota: Conteo realizado usando token.is_alpha de spacy\n",
      "      Se excluyen: puntuaci√≥n, espacios, n√∫meros y s√≠mbolos\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Calcular el promedio de palabras por grupo (odio y no odio) usando spacy\n",
    "# Algoritmo para determinar si un comentario es de odio o no odio\n",
    "# Criterio: \n",
    "# - NO ODIO: INTENSIDAD == 0.0 y TIPO DE ODIO es NaN/vac√≠o\n",
    "# - ODIO: INTENSIDAD > 0.0 o TIPO DE ODIO no es NaN/vac√≠o\n",
    "\n",
    "def clasificar_odio(intensidad, tipo_odio):\n",
    "    tipo_odio_vacio = pd.isna(tipo_odio) or tipo_odio == '' or str(tipo_odio).strip() == ''\n",
    "    \n",
    "    if (intensidad == 0.0 or intensidad == 0) and tipo_odio_vacio:\n",
    "        return 'no_odio'\n",
    "    else:\n",
    "        return 'odio'\n",
    "\n",
    "clasificacion = []\n",
    "for i in range(len(data)):\n",
    "    intensidad = data['INTENSIDAD'].iloc[i]\n",
    "    tipo_odio = data['TIPO DE ODIO'].iloc[i]\n",
    "    clasificacion.append(clasificar_odio(intensidad, tipo_odio))\n",
    "\n",
    "data['CLASIFICACION'] = clasificacion\n",
    "\n",
    "palabras_odio = []\n",
    "palabras_no_odio = []\n",
    "\n",
    "# Contar palabras usando spacy con token.is_alpha\n",
    "# token.is_alpha identifica tokens alfab√©ticos (excluye puntuaci√≥n, espacios, n√∫meros, s√≠mbolos)\n",
    "for i in range(len(doc)):\n",
    "    # Usar token.is_alpha de spacy para contar solo palabras alfab√©ticas\n",
    "    palabras = sum(1 for token in doc[i] if token.is_alpha)\n",
    "    \n",
    "    if clasificacion[i] == 'odio':\n",
    "        palabras_odio.append(palabras)\n",
    "    else:\n",
    "        palabras_no_odio.append(palabras)\n",
    "\n",
    "promedio_odio = sum(palabras_odio) / len(palabras_odio) if palabras_odio else 0\n",
    "promedio_no_odio = sum(palabras_no_odio) / len(palabras_no_odio) if palabras_no_odio else 0\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CLASIFICACI√ìN DE COMENTARIOS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Comentarios de ODIO: {len(palabras_odio):,}\")\n",
    "print(f\"Comentarios de NO ODIO: {len(palabras_no_odio):,}\")\n",
    "print(\"PROMEDIO DE PALABRAS POR GRUPO (USANDO SPACY)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Promedio de palabras en comentarios de ODIO: {promedio_odio:.2f}\")\n",
    "print(f\"Promedio de palabras en comentarios de NO ODIO: {promedio_no_odio:.2f}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Nota: Conteo realizado usando token.is_alpha de spacy\")\n",
    "print(f\"      Se excluyen: puntuaci√≥n, espacios, n√∫meros y s√≠mbolos\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aqu√≠, debajo de la l√≠nea, la explicaci√≥n de tu respuesta</b>\n",
    "<hr>\n",
    " \n",
    "Para calcular el promedio de palabras en cada grupo (odio y no odio), utilizamos spacy para contar las palabras en cada comentario. El proceso se realiza de la siguiente manera:\n",
    "\n",
    "1. **Clasificaci√≥n de comentarios**: Primero clasificamos cada comentario como \"odio\" o \"no odio\" bas√°ndonos en los criterios:\n",
    "   - **NO ODIO**: INTENSIDAD == 0.0 y TIPO DE ODIO es NaN/vac√≠o\n",
    "   - **ODIO**: INTENSIDAD > 0.0 o TIPO DE ODIO no es NaN/vac√≠o\n",
    "\n",
    "2. **Conteo de palabras con spacy**: Para cada documento procesado por spacy, utilizamos el atributo `token.is_alpha` para contar √∫nicamente los tokens que son palabras alfab√©ticas. Este m√©todo es m√°s preciso y consistente con los ejercicios anteriores porque:\n",
    "   - Excluye autom√°ticamente puntuaci√≥n (`token.is_punct`)\n",
    "   - Excluye espacios (`token.is_space`)\n",
    "   - Excluye n√∫meros (`token.is_digit`)\n",
    "   - Excluye s√≠mbolos y caracteres especiales\n",
    "\n",
    "3. **Agrupaci√≥n**: Almacenamos el n√∫mero de palabras de cada comentario en listas separadas seg√∫n su clasificaci√≥n (odio o no odio).\n",
    "\n",
    "4. **C√°lculo de promedios**: Finalmente, calculamos el promedio para cada grupo dividiendo la suma total de palabras entre el n√∫mero de comentarios en cada grupo.\n",
    "\n",
    "**Ventajas de usar spacy con token.is_alpha**:\n",
    "- **Consistencia**: Utiliza el mismo m√©todo de conteo que los ejercicios anteriores (#2 y #3)\n",
    "- **Precisi√≥n**: La tokenizaci√≥n inteligente de spacy respeta las reglas del idioma espa√±ol\n",
    "- **Eficiencia**: Los atributos predefinidos facilitan el filtrado preciso sin necesidad de m√∫ltiples condiciones\n",
    "- **Claridad**: El c√≥digo es m√°s legible y mantenible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 5.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio) ¬øCu√°l es el n√∫mero promedio de oraciones en los comentarios de cada grupo?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PROMEDIO DE ORACIONES POR GRUPO (USANDO SPACY)\n",
      "============================================================\n",
      "Comentarios de ODIO: 748\n",
      "Comentarios de NO ODIO: 252\n",
      "============================================================\n",
      "Promedio de oraciones en comentarios de ODIO: 1.76\n",
      "Promedio de oraciones en comentarios de NO ODIO: 5.60\n",
      "============================================================\n",
      "Nota: Segmentaci√≥n realizada usando doc.sents de spacy\n",
      "      spacy detecta autom√°ticamente los l√≠mites de oraciones\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Contar el n√∫mero de oraciones en cada comentario usando spacy\n",
    "# spacy segmenta autom√°ticamente las oraciones usando el atributo .sents del objeto Doc\n",
    "\n",
    "oraciones_odio = []\n",
    "oraciones_no_odio = []\n",
    "\n",
    "for i in range(len(doc)):\n",
    "    num_oraciones = len(list(doc[i].sents))\n",
    "    \n",
    "    if clasificacion[i] == 'odio':\n",
    "        oraciones_odio.append(num_oraciones)\n",
    "    else:\n",
    "        oraciones_no_odio.append(num_oraciones)\n",
    "\n",
    "# Calcular promedios\n",
    "promedio_oraciones_odio = sum(oraciones_odio) / len(oraciones_odio) if oraciones_odio else 0\n",
    "promedio_oraciones_no_odio = sum(oraciones_no_odio) / len(oraciones_no_odio) if oraciones_no_odio else 0\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PROMEDIO DE ORACIONES POR GRUPO (USANDO SPACY)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Comentarios de ODIO: {len(oraciones_odio):,}\")\n",
    "print(f\"Comentarios de NO ODIO: {len(oraciones_no_odio):,}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Promedio de oraciones en comentarios de ODIO: {promedio_oraciones_odio:.2f}\")\n",
    "print(f\"Promedio de oraciones en comentarios de NO ODIO: {promedio_oraciones_no_odio:.2f}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Nota: Segmentaci√≥n realizada usando doc.sents de spacy\")\n",
    "print(f\"      spacy detecta autom√°ticamente los l√≠mites de oraciones\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aqu√≠, debajo de la l√≠nea, la explicaci√≥n de tu respuesta</b>\n",
    "<hr>\n",
    " \n",
    "Para calcular el n√∫mero promedio de oraciones en cada grupo (odio y no odio), utilizamos la capacidad de segmentaci√≥n de oraciones que proporciona spacy a trav√©s del atributo `.sents` del objeto `Doc`. Este atributo devuelve un generador de objetos `Span` que representan cada oraci√≥n detectada en el texto.\n",
    "\n",
    "El algoritmo implementado:\n",
    "1. Itera sobre cada documento procesado en la lista `doc`\n",
    "2. Cuenta el n√∫mero de oraciones usando `len(list(doc[i].sents))`, convirtiendo el generador a lista para poder contar\n",
    "3. Clasifica cada comentario seg√∫n la lista `clasificacion` creada en el ejercicio anterior\n",
    "4. Almacena el n√∫mero de oraciones en listas separadas seg√∫n el grupo (odio o no odio)\n",
    "5. Calcula el promedio dividiendo la suma total de oraciones entre el n√∫mero de comentarios en cada grupo\n",
    "\n",
    "Esta caracter√≠stica es importante porque permite analizar la complejidad estructural de los comentarios. Los comentarios con m√°s oraciones suelen ser m√°s elaborados y estructurados, mientras que los comentarios con menos oraciones pueden ser m√°s directos y concisos. Esta diferencia puede ser relevante para caracterizar los patrones de comunicaci√≥n en cada grupo.\n",
    "\n",
    "**Ventajas de usar spacy para segmentaci√≥n de oraciones**:\n",
    "- **Precisi√≥n**: spacy utiliza modelos entrenados que reconocen correctamente los l√≠mites de oraciones en espa√±ol\n",
    "- **Robustez**: Maneja casos complejos como abreviaciones, n√∫meros, puntuaci√≥n m√∫ltiple, etc.\n",
    "- **Consistencia**: Utiliza el mismo pipeline de procesamiento que el resto de los an√°lisis\n",
    "- **Eficiencia**: La segmentaci√≥n se realiza autom√°ticamente durante el procesamiento inicial del texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 6.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio) ¬øCu√°l es el porcentaje de comentarios que contienen entidades NER en cada grupo?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PORCENTAJE DE COMENTARIOS CON ENTIDADES NER (USANDO SPACY)\n",
      "============================================================\n",
      "Comentarios de ODIO: 748\n",
      "  - Con entidades NER: 264\n",
      "  - Porcentaje: 35.29%\n",
      "============================================================\n",
      "Comentarios de NO ODIO: 252\n",
      "  - Con entidades NER: 96\n",
      "  - Porcentaje: 38.10%\n",
      "============================================================\n",
      "Nota: Detecci√≥n realizada usando doc.ents de spacy\n",
      "      spacy identifica autom√°ticamente personas, organizaciones, lugares, etc.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Calcular el porcentaje de comentarios que contienen entidades NER usando spacy\n",
    "# spacy detecta autom√°ticamente entidades nombradas (personas, organizaciones, lugares, etc.)\n",
    "# usando el atributo .ents del objeto Doc\n",
    "\n",
    "comentarios_con_ner_odio = 0\n",
    "comentarios_con_ner_no_odio = 0\n",
    "total_comentarios_odio = 0\n",
    "total_comentarios_no_odio = 0\n",
    "\n",
    "# Iterar sobre cada documento procesado por spacy\n",
    "for i in range(len(doc)):\n",
    "    # Verificar si el documento contiene entidades NER\n",
    "    # doc[i].ents es una tupla de objetos Span que representan las entidades encontradas\n",
    "    tiene_ner = len(doc[i].ents) > 0\n",
    "    \n",
    "    # Clasificar seg√∫n el grupo y contar\n",
    "    if clasificacion[i] == 'odio':\n",
    "        total_comentarios_odio += 1\n",
    "        if tiene_ner:\n",
    "            comentarios_con_ner_odio += 1\n",
    "    else:\n",
    "        total_comentarios_no_odio += 1\n",
    "        if tiene_ner:\n",
    "            comentarios_con_ner_no_odio += 1\n",
    "\n",
    "# Calcular porcentajes\n",
    "porcentaje_ner_odio = (comentarios_con_ner_odio / total_comentarios_odio * 100) if total_comentarios_odio > 0 else 0\n",
    "porcentaje_ner_no_odio = (comentarios_con_ner_no_odio / total_comentarios_no_odio * 100) if total_comentarios_no_odio > 0 else 0\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PORCENTAJE DE COMENTARIOS CON ENTIDADES NER (USANDO SPACY)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Comentarios de ODIO: {total_comentarios_odio:,}\")\n",
    "print(f\"  - Con entidades NER: {comentarios_con_ner_odio:,}\")\n",
    "print(f\"  - Porcentaje: {porcentaje_ner_odio:.2f}%\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Comentarios de NO ODIO: {total_comentarios_no_odio:,}\")\n",
    "print(f\"  - Con entidades NER: {comentarios_con_ner_no_odio:,}\")\n",
    "print(f\"  - Porcentaje: {porcentaje_ner_no_odio:.2f}%\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Nota: Detecci√≥n realizada usando doc.ents de spacy\")\n",
    "print(f\"      spacy identifica autom√°ticamente personas, organizaciones, lugares, etc.\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aqu√≠, debajo de la l√≠nea, la explicaci√≥n de tu respuesta</b>\n",
    "<hr>\n",
    " \n",
    "Para calcular el porcentaje de comentarios que contienen entidades NER (Named Entity Recognition) en cada grupo, utilizamos la capacidad de reconocimiento de entidades nombradas que proporciona spacy a trav√©s del atributo `.ents` del objeto `Doc`.\n",
    "\n",
    "El proceso se realiza de la siguiente manera:\n",
    "\n",
    "1. **Detecci√≥n de entidades NER con spacy**: Para cada documento procesado, verificamos si contiene entidades nombradas usando `len(doc[i].ents) > 0`. El atributo `.ents` devuelve una tupla de objetos `Span` que representan las entidades encontradas en el texto, tales como:\n",
    "   - **PERSON**: Nombres de personas\n",
    "   - **ORG**: Organizaciones\n",
    "   - **LOC**: Ubicaciones geogr√°ficas\n",
    "   - **MISC**: Entidades miscel√°neas\n",
    "   - Y otros tipos seg√∫n el modelo de spacy utilizado\n",
    "\n",
    "2. **Clasificaci√≥n y conteo**: Para cada comentario:\n",
    "   - Verificamos si contiene al menos una entidad NER\n",
    "   - Clasificamos el comentario seg√∫n su grupo (odio o no odio) usando la lista `clasificacion`\n",
    "   - Contamos el total de comentarios en cada grupo\n",
    "   - Contamos cu√°ntos comentarios en cada grupo contienen entidades NER\n",
    "\n",
    "3. **C√°lculo de porcentajes**: Calculamos el porcentaje dividiendo el n√∫mero de comentarios con NER entre el total de comentarios en cada grupo, multiplicado por 100.\n",
    "\n",
    "**Importancia de esta caracter√≠stica**:\n",
    "- Las entidades NER pueden indicar referencias a personas, lugares u organizaciones espec√≠ficas\n",
    "- Los comentarios de odio pueden tener patrones diferentes en cuanto a la menci√≥n de entidades\n",
    "- Esta caracter√≠stica ayuda a entender si los comentarios hacen referencias espec√≠ficas a entidades nombradas\n",
    "\n",
    "**Ventajas de usar spacy para NER**:\n",
    "- **Precisi√≥n**: spacy utiliza modelos entrenados espec√≠ficamente para espa√±ol que reconocen correctamente entidades nombradas\n",
    "- **Automatizaci√≥n**: La detecci√≥n se realiza autom√°ticamente durante el procesamiento del texto\n",
    "- **Consistencia**: Utiliza el mismo pipeline de procesamiento que el resto de los an√°lisis\n",
    "- **Tipado**: Cada entidad tiene un label que indica su tipo, permitiendo an√°lisis m√°s detallados si se requiere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 16pt; font-weight: bold; color: #0098cd;\">Plantea tus propias preguntas</span>\n",
    "\n",
    "<span><b>Plantea al menos 4 caracter√≠sticas</b> del texto cuyo an√°lisis permita una caracterizaci√≥n completa del texto. Puedes utilizar recomendaciones proporcionadas por la IA Generativa, si as√≠ lo deseas. Para cada una de las caracter√≠sticas planteadas, obt√©n valores separados para los grupos ODIO/NO-ODIO.</span>\n",
    "\n",
    "<span>En la explicaci√≥n aportada, deber√°s <b>explicar el significado de la caracter√≠stica planteada</b> as√≠ como la importancia de √©sta en la caracterizaci√≥n del texto.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Caracter√≠stica adicional 1.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Cantidad de nombres propios en los comentarios</span>\n",
    "<b>Definici√≥n:</b>\n",
    "N√∫mero de entidades de tipo persona (PER) u organizaci√≥n (ORG) en cada comentario.\n",
    "<b>Motivaci√≥n:</b>\n",
    "Los comentarios de odio suelen mencionar personas o grupos espec√≠ficos. Contar estas menciones permite diferenciar mensajes de odio de comentarios neutrales.\n",
    "<b>Hip√≥tesis:</b>\n",
    "‚ÄúLos comentarios de odio mencionan m√°s frecuentemente personas o entidades que los comentarios de no odio.‚Äù\n",
    "<b>Explicaci√≥n:</b>\n",
    "Esta caracter√≠stica refleja la focalizaci√≥n del mensaje hacia individuos o grupos, y puede ser √∫til para an√°lisis estad√≠sticos o modelos de clasificaci√≥n de mensajes de odio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aqu√≠, debajo de la l√≠nea, la explicaci√≥n de la caracter√≠stica propuesta y su motivaci√≥n. Incluye tambi√©n una explicaci√≥n del c√≥digo fuente aportado.</b>\n",
    "<hr>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Caracter√≠stica adicional 2.</span>\n",
    "\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Cantidad de adjetivos en los comentarios</span>\n",
    "\n",
    "<b>Definici√≥n:</b>\n",
    "N√∫mero de adjetivos presentes en cada comentario.\n",
    "\n",
    "<b>Motivaci√≥n:</b>\n",
    "Los comentarios de odio suelen contener descripciones calificativas o insultos que utilizan adjetivos para referirse a personas o entidades. Contar los adjetivos ayuda a diferenciar comentarios de odio de los no ofensivos.\n",
    "\n",
    "<b>Hip√≥tesis:</b>\n",
    "\n",
    "‚ÄúLos comentarios de odio contienen m√°s adjetivos que los comentarios de no odio, reflejando descripciones directas sobre personas o grupos.‚Äù\n",
    "\n",
    "<b>Explicaci√≥n:</b>\n",
    "Esta caracter√≠stica permite analizar c√≥mo se utilizan los adjetivos para calificar o atacar a individuos o entidades. Es √∫til para entender la intensidad y el tipo de lenguaje empleado en mensajes de odio y puede servir como variable para an√°lisis estad√≠sticos o modelos de detecci√≥n de odio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aqu√≠, debajo de la l√≠nea, la explicaci√≥n de la caracter√≠stica propuesta y su motivaci√≥n. Incluye tambi√©n una explicaci√≥n del c√≥digo fuente aportado.</b>\n",
    "<hr>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Caracter√≠stica adicional 3.</span>\n",
    "\n",
    "\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">[INDICA AQU√ç LA CARACTER√çSTICA QUE PROPONES]</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Caracter√≠stica adicional 3.</span>\n",
    "\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Relaci√≥n entre adjetivos y sustantivos en los comentarios</span>\n",
    "\n",
    "<b>Definici√≥n:</b>\n",
    "Proporci√≥n de adjetivos respecto a sustantivos en cada comentario.\n",
    "\n",
    "<b>Motivaci√≥n:</b>\n",
    "Esta medida permite analizar si los comentarios de odio tienden a calificar directamente a las personas o entidades mencionadas. Comparar la cantidad de adjetivos con la de sustantivos ayuda a evaluar el enfoque descriptivo o valorativo del mensaje.\n",
    "\n",
    "<b>Hip√≥tesis:</b>\n",
    "\n",
    "‚ÄúEn los comentarios de odio, es m√°s com√∫n que se utilicen adjetivos junto con nombres propios para realizar comentarios negativos sobre el sujeto del ataque.‚Äù\n",
    "\n",
    "<b>Explicaci√≥n:</b>\n",
    "Al relacionar adjetivos con sustantivos dentro de un mismo comentario, podemos identificar patrones en los que los usuarios describen o critican a individuos o grupos espec√≠ficos. Esta caracter√≠stica aporta informaci√≥n sobre el estilo y la intenci√≥n del lenguaje empleado, y es √∫til para an√°lisis estad√≠sticos y modelos de detecci√≥n de odio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incluye aqu√≠ el c√≥digo generado para poder responder a tu pregunta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aqu√≠, debajo de la l√≠nea, la explicaci√≥n de la caracter√≠stica propuesta y su motivaci√≥n. Incluye tambi√©n una explicaci√≥n del c√≥digo fuente aportado.</b>\n",
    "<hr>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Caracter√≠stica adicional 4.</span>\n",
    "\n",
    "\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">[INDICA AQU√ç LA CARACTER√çSTICA QUE PROPONES]</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Caracter√≠stica adicional 4.</span>\n",
    "\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Relaci√≥n entre adverbios y adjetivos en los comentarios</span>\n",
    "\n",
    "<b>Definici√≥n:</b>\n",
    "Proporci√≥n de adverbios respecto a adjetivos en cada comentario.\n",
    "\n",
    "<b>Motivaci√≥n:</b>\n",
    "Los comentarios de odio suelen usar adverbios para intensificar o exagerar los adjetivos, reflejando opiniones sesgadas o polarizadas sobre una persona o entidad. Analizar esta relaci√≥n permite entender la intensidad del lenguaje empleado.\n",
    "\n",
    "<b>Hip√≥tesis:</b>\n",
    "\n",
    "‚ÄúLos comentarios negativos tienden a utilizar m√°s adverbios para hiperbolizar ciertos atributos o situaciones, mostrando un mayor grado de intensidad o disgusto.‚Äù\n",
    "\n",
    "<b>Explicaci√≥n:</b>\n",
    "Al evaluar la relaci√≥n entre adverbios y adjetivos, podemos identificar c√≥mo los usuarios exageran cualidades o situaciones para reforzar su mensaje de odio. Esta caracter√≠stica aporta informaci√≥n sobre la carga emocional y la polarizaci√≥n del comentario, siendo √∫til para an√°lisis estad√≠sticos o modelos de detecci√≥n de mensajes de odio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aqu√≠, debajo de la l√≠nea, la explicaci√≥n de la caracter√≠stica propuesta y su motivaci√≥n. Incluye tambi√©n una explicaci√≥n del c√≥digo fuente aportado.</b>\n",
    "<hr>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 16pt; font-weight: bold; color: #0098cd;\">Reflexi√≥n final</span>\n",
    "\n",
    "<span>Una de las utilidades de la caracterizaci√≥n de texto es que nos sirve como etapa de <i>feature-extraction</i> (extraci√≥n de caracter√≠sticas) de cara a un posterior sistema de clasificaci√≥n. Es pertinente, por tanto, reflexionar sobre la capacidad discriminatoria de cada una de las caracter√≠sticas extra√≠das. </span>\n",
    "\n",
    "<span> Responde, para ello, a la siguiente pregunta.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Reflexi√≥n final.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¬øEs posible utilizar alguna de las caracter√≠sticas extra√≠das en las preguntas anteriores para determinar si un mensaje contiene odio? Justifica tu respuesta con el an√°lisis estad√≠stico que consideres necesario.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incluye aqu√≠ el c√≥digo generado para poder responder a tu pregunta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aqu√≠, debajo de la l√≠nea, la explicaci√≥n de tu respuesta</b>\n",
    "<hr>\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
